{
  "_readme": "Arbiter multi-model config. Edit this file then run: arbiter run. See README.md.",
  "schema_version": "1.0.0",
  "run": {
    "run_id": "pending",
    "seed": 777777
  },
  "question": {
    "text": "How should teams balance speed and safety in AI deployment?",
    "question_id": "multi_model_question_1"
  },
  "sampling": {
    "models": [
      { "model": "openai/gpt-4o-mini", "weight": 0.5 },
      { "model": "anthropic/claude-3.5-sonnet", "weight": 0.3 },
      { "model": "google/gemini-1.5-pro", "weight": 0.2 }
    ],
    "personas": [
      { "persona": "stub_persona_neutral", "weight": 0.5 },
      { "persona": "stub_persona_expert", "weight": 0.5 }
    ],
    "protocols": [
      { "protocol": "stub_protocol_independent_sampling", "weight": 1 }
    ],
    "decode": {
      "temperature": 0.6,
      "top_p": 0.95,
      "max_tokens": 512
    }
  },
  "protocol": {
    "type": "independent",
    "timeouts": {
      "per_call_timeout_ms": 90000,
      "per_call_max_retries": 2,
      "total_trial_timeout_ms": 300000
    }
  },
  "execution": {
    "k_max": 20,
    "batch_size": 5,
    "workers": 3,
    "retry_policy": {
      "max_retries": 0,
      "backoff_ms": 0
    },
    "stop_mode": "advisor",
    "k_min": 0,
    "k_min_count_rule": "k_eligible"
  },
  "measurement": {
    "embedding_model": "openai/text-embedding-3-small",
    "embed_text_strategy": "outcome_only",
    "novelty_threshold": 0.85,
    "clustering": {
      "enabled": false,
      "algorithm": "online_leader",
      "tau": 0.85,
      "centroid_update_rule": "fixed_leader",
      "cluster_limit": 500,
      "stop_mode": "disabled"
    }
  },
  "output": {
    "runs_dir": "runs"
  }
}
