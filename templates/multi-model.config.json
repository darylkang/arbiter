{
  "_readme": "Arbiter multi-model template (independent). Edit then run: arbiter run.",
  "template_id": "multi-model",
  "display_name": "Multi-model mix (independent)",
  "description": "Mix multiple providers for heterogeneity coverage.",
  "schema_version": "1.0.0",
  "run": {
    "run_id": "pending",
    "seed": 424242
  },
  "question": {
    "text": "How should teams balance speed and safety in AI deployment?",
    "question_id": "multi_model_q1"
  },
  "sampling": {
    "models": [
      { "model": "openai/gpt-4o-mini-2024-07-18", "weight": 1 },
      { "model": "anthropic/claude-sonnet-4", "weight": 1 },
      { "model": "google/gemini-2.0-flash-001", "weight": 1 }
    ],
    "personas": [
      { "persona": "persona_neutral", "weight": 0.5 },
      { "persona": "persona_skeptical", "weight": 0.5 }
    ],
    "protocols": [
      { "protocol": "protocol_independent_v1_system", "weight": 1 }
    ],
    "decode": {
      "temperature": { "min": 0.5, "max": 0.8 },
      "top_p": 0.95,
      "max_tokens": 512
    }
  },
  "protocol": {
    "type": "independent",
    "timeouts": {
      "per_call_timeout_ms": 90000,
      "per_call_max_retries": 2,
      "total_trial_timeout_ms": 300000
    }
  },
  "execution": {
    "k_max": 48,
    "batch_size": 6,
    "workers": 4,
    "retry_policy": {
      "max_retries": 0,
      "backoff_ms": 0
    },
    "stop_policy": {
      "novelty_epsilon": 0.1,
      "similarity_threshold": 0.85,
      "patience": 3
    },
    "stop_mode": "advisor",
    "k_min": 24,
    "k_min_count_rule": "k_eligible"
  },
  "measurement": {
    "embedding_model": "openai/text-embedding-3-small",
    "embed_text_strategy": "outcome_only",
    "novelty_threshold": 0.85,
    "clustering": {
      "enabled": false,
      "algorithm": "online_leader",
      "tau": 0.85,
      "centroid_update_rule": "fixed_leader",
      "cluster_limit": 500,
      "stop_mode": "disabled"
    }
  },
  "output": {
    "runs_dir": "runs"
  }
}
